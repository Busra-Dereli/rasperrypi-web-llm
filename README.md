# ğŸ¤– Raspberry Pi 5 LLM Chatbot

Bu proje, **Raspberry Pi 5** Ã¼zerinde Ã§alÄ±ÅŸan, web tabanlÄ±, konteynerize edilmiÅŸ bir **LLM (TinyLlama)** tabanlÄ± sohbet uygulamasÄ±dÄ±r. ArayÃ¼zÃ¼ modern bir UI kit ile geliÅŸtirilmiÅŸ, arka planda Python ile yazÄ±lmÄ±ÅŸ bir API Ã§alÄ±ÅŸmaktadÄ±r. Proje, dÃ¼ÅŸÃ¼k gÃ¼Ã§lÃ¼ donanÄ±mlarda bÃ¼yÃ¼k dil modelleriyle sohbet uygulamalarÄ± geliÅŸtirmek iÃ§in Ã¶rnek bir altyapÄ± sunar.

---

## ğŸ“Œ Teknoloji YÄ±ÄŸÄ±nÄ±

| BileÅŸen              | Teknoloji                              	     |
|----------------------|-----------------------------------------------|
| ğŸ§  LLM Modeli       | [TinyLlama](https://huggingface.co/TinyLlama) |
| ğŸ’» Cihaz            | Raspberry Pi 5                                |
| ğŸ§ Ä°ÅŸletim Sistemi  | Raspberry Pi OS (Debian tabanlÄ±)              |
| ğŸ”§ Backend          | Python + Uvicorn (FastAPI ile)                |
| ğŸ§ª API Test         | Postman                                       |
| ğŸ“¦ Containerization | Docker                                        |
| ğŸ’» Frontend         | React                                         |
| ğŸ¨ UI               | Tailwind CSS + Shadcn                         |
| ğŸ”’ GÃ¼venlik         | Letâ€™s Encrypt + Certbot + Cloudflare          |
| ğŸ“œ Logging          | Grafana Loki                                  |
| ğŸŒ Versiyon Kontrol | Git + GitHub                                  |
| ğŸ—‚ï¸ Proje YÃ¶netimi   | Jira                                          |


## ğŸ“ Proje YapÄ±sÄ±
```
raspi-llm-chatbot/
â”‚
â”œâ”€â”€ backend/
â”‚ â”œâ”€â”€ app/
â”‚ â”‚ â”œâ”€â”€ main.py 		# FastAPI ile tanÄ±mlÄ± endpoint'ler
â”‚ â”‚ â”œâ”€â”€ llm_handler.py		# TinyLlama modeliyle etkileÅŸim
â”‚ â”‚ â””â”€â”€ utils.py 			# YardÄ±mcÄ± fonksiyonlar
â”‚ â”œâ”€â”€ requirements.txt 		# Python baÄŸÄ±mlÄ±lÄ±klarÄ±
â”‚ â””â”€â”€ Dockerfile 			# Backend container'Ä±
â”‚
â”œâ”€â”€ frontend/
â”‚ â”œâ”€â”€ public/
â”‚ â”œâ”€â”€ src/
â”‚ â”‚ â”œâ”€â”€ App.tsx 		# React ana bileÅŸen
â”‚ â”‚ â”œâ”€â”€ components/ 		# Chat UI bileÅŸenleri (Shadcn)
â”‚ â”‚ â””â”€â”€ services/ 		# API istekleri
â”‚ â”œâ”€â”€ tailwind.config.js
â”‚ â””â”€â”€ Dockerfile 			# Frontend container'Ä±
â”‚
â”œâ”€â”€ nginx/
â”‚ â”œâ”€â”€ default.conf 		# Reverse proxy ayarlarÄ±
â”‚ â””â”€â”€ certbot/ 			# SSL dosyalarÄ±
â”‚
â”œâ”€â”€ docker-compose.yml 	# TÃ¼m servisi ayaÄŸa kaldÄ±rÄ±r
â”œâ”€â”€ .env 				# Ortam deÄŸiÅŸkenleri
â”œâ”€â”€ README.md 			# Bu dosya
â””â”€â”€ LICENSE
```

## ğŸš€ Kurulum
> **Not:** Proje Raspberry Pi 5 Ã¼zerinde test edilmemiÅŸtir.
1. Gerekli yazÄ±lÄ±mlar:
   - Docker
   - Docker Compose
   - Git
   - Python 3.9+

2. Reponun klonlanmasÄ±:
```
    git clone https://github.com/kullaniciadi/raspi-llm-chatbot.git
    cd raspi-llm-chatbot
```
3.	Ortam deÄŸiÅŸkenlerini .env dosyasÄ±na yazÄ±n:
```
   	API_URL=http://localhost:8000
   	MODEL_NAME=tinyllama/TinyLlama-1.1B-Chat-v1.0
```
4.	Docker container'larÄ±nÄ± baÅŸlatÄ±n:
```
	  docker-compose up --build
```
5.	ArayÃ¼zÃ¼ tarayÄ±cÄ±da aÃ§Ä±n:
```
	  http://<raspberrypi-local-ip>
```
ğŸ§  TinyLlama Modeli
Projede kullanÄ±lan model: TinyLlama-1.1B-Chat
SeÃ§im nedenleri:
â€¢	Raspberry Pi gibi sÄ±nÄ±rlÄ± donanÄ±mda Ã§alÄ±ÅŸabilecek kÃ¼Ã§Ã¼k yapÄ±da olmasÄ±
â€¢	Chat iÃ§in optimize edilmiÅŸ olmasÄ±
â€¢	Hugging Face Transformers ile kolay entegrasyon
Model, ilk Ã§alÄ±ÅŸtÄ±rmada otomatik olarak indirilecektir. Dilerseniz modeli Ã¶nceden indirerek llm_handler.py dosyasÄ±ndaki AutoModelForCausalLM.from_pretrained() fonksiyonunda path olarak gÃ¶sterebilirsiniz.
________________________________________
ğŸ–¼ï¸ Chat ArayÃ¼zÃ¼
UI ÅŸu bileÅŸenleri kullanÄ±r:
â€¢	React: Modern web uygulama Ã§atÄ±sÄ±
â€¢	Tailwind CSS: Stil oluÅŸturma
â€¢	Shadcn UI: Chat arayÃ¼z bileÅŸenleri (chat bubble, input, dark mode vs.)
Chat arayÃ¼zÃ¼ kullanÄ±cÄ± mesajÄ±nÄ± backendâ€™e gÃ¶nderir ve TinyLlama yanÄ±tÄ±nÄ± ekrana yansÄ±tÄ±r.
________________________________________
ğŸ”’ GÃ¼venlik
â€¢	HTTPS kurulumu iÃ§in Let's Encrypt + Certbot yapÄ±landÄ±rÄ±lmÄ±ÅŸtÄ±r.
â€¢	Cloudflare Ã¼zerinden DNS ve DDoS korumasÄ± entegredir.
â€¢	nginx reverse proxy SSL trafiÄŸini yÃ¶nlendirir.
________________________________________
ğŸ“ˆ GÃ¶zlem ve Loglama
â€¢	API loglarÄ± Grafana Loki ile toplanÄ±r.
â€¢	Promtail aracÄ±yla container loglarÄ± alÄ±nÄ±r.
â€¢	Ä°steÄŸe baÄŸlÄ± olarak Grafana Dashboard kurulumu yapÄ±labilir.
________________________________________
ğŸ” API Testi
TÃ¼m endpoint'ler Postman koleksiyonlarÄ± ile test edilebilir. docs/ dizininde .postman_collection.json dosyasÄ± yer almaktadÄ±r.

ğŸ“œ Lisans
Bu proje, [GNU General Public License v3.0 (GPL-3.0)](https://www.gnu.org/licenses/gpl-3.0.html) lisansÄ± ile lisanslanmÄ±ÅŸtÄ±r.
> Bu lisans, projenizin Ã¶zgÃ¼r yazÄ±lÄ±m olmasÄ±nÄ± saÄŸlar. Kaynak kodu deÄŸiÅŸtirmek ve paylaÅŸmak serbesttir. Ancak, daÄŸÄ±tÄ±lan tÃ¼rev Ã§alÄ±ÅŸmalarÄ±n da aynÄ± lisansla lisanslanmasÄ± gerekir (copyleft).


ğŸ¤ KatkÄ±da Bulun
1.	Forkâ€™la
2.	Yeni branch oluÅŸtur: git checkout -b feature/yenilik
3.	Commit yap: git commit -m 'Yeni Ã¶zellik eklendi'
4.	Push et: git push origin feature/yenilik
5.	PR gÃ¶nder!

